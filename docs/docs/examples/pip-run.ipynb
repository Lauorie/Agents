{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "byPgKYhAE6gn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = 'sk-fGyaye1fSHhS1m4b8dDaE0656f204219Bc8dAa5340B4Bc2'\n",
        "os.environ['OPENAI_BASE_URL'] = 'https://one-api.huayungpt.com/v1'\n",
        "os.environ['TAVILY_API_KEY'] = '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' # Get a free key here: https://app.tavily.com"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U gpt-researcher nest_asyncio"
      ],
      "metadata": {
        "id": "-rXET3OZLxwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio # required for notebooks\n",
        "nest_asyncio.apply()\n",
        "\n",
        "from gpt_researcher import GPTResearcher\n",
        "import asyncio\n",
        "\n",
        "async def get_report(query: str, report_type: str) -> str:\n",
        "    researcher = GPTResearcher(query, report_type)\n",
        "    research_result = await researcher.conduct_research()\n",
        "    report = await researcher.write_report()\n",
        "\n",
        "    # Get additional information\n",
        "    research_context = researcher.get_research_context()\n",
        "    research_costs = researcher.get_costs()\n",
        "    research_images = researcher.get_research_images()\n",
        "    research_sources = researcher.get_research_sources()\n",
        "\n",
        "    return report, research_context, research_costs, research_images, research_sources\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    query = \" Gen AI åœ¨æœåŠ¡ä¸­çš„å®é™…æˆæœ\"\n",
        "    report_type = \"research_report\"\n",
        "\n",
        "    report, context, costs, images, sources = asyncio.run(get_report(query, report_type))\n",
        "\n",
        "    print(\"Report:\")\n",
        "    print(report)\n",
        "    print(\"\\nResearch Costs:\")\n",
        "    print(costs)\n",
        "    print(\"\\nResearch Images:\")\n",
        "    print(images)\n",
        "    print(\"\\nResearch Sources:\")\n",
        "    print(sources)"
      ],
      "metadata": {
        "id": "KWZe2InrL0ji",
        "outputId": "8fd4026e-af40-4972-cd6c-31e6cff61ad4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     [07:10:19] ğŸ” Starting the research task for ' Gen AI åœ¨æœåŠ¡ä¸­çš„å®é™…æˆæœ'...\n",
            "INFO:     [07:10:19] ğŸ¤– AI Technology Agent\n",
            "INFO:     [07:10:19] ğŸŒ Browsing the web to learn more about the task:  Gen AI åœ¨æœåŠ¡ä¸­çš„å®é™…æˆæœ...\n",
            "INFO:     [07:10:20] ğŸ¤” Planning the research strategy and subtasks (this may take a minute)...\n",
            "WARNING:gpt_researcher.actions.query_processing:Error with strategic LLM: Error code: 503 - {'error': {'message': 'å½“å‰åˆ†ç»„ vip ä¸‹å¯¹äºæ¨¡å‹ o1-preview æ— å¯ç”¨æ¸ é“ (request id: 202412061510235943598816UzixCT4)', 'type': 'new_api_error'}}. Falling back to smart LLM.\n",
            "INFO:     [07:10:26] ğŸ—‚ï¸ I will conduct my research based on the following queries: ['Generative AI impact on business services 2024', 'Real results of Gen AI in service industries', 'Generative AI productivity boost in operations', 'McKinsey insights on Gen AI in enterprise technology', ' Gen AI åœ¨æœåŠ¡ä¸­çš„å®é™…æˆæœ']...\n",
            "INFO:     [07:10:26] \n",
            "ğŸ” Running research for 'Generative AI impact on business services 2024'...\n",
            "INFO:     [07:10:26] \n",
            "ğŸ” Running research for 'Real results of Gen AI in service industries'...\n",
            "INFO:     [07:10:26] \n",
            "ğŸ” Running research for 'Generative AI productivity boost in operations'...\n",
            "INFO:     [07:10:26] \n",
            "ğŸ” Running research for 'McKinsey insights on Gen AI in enterprise technology'...\n",
            "INFO:     [07:10:26] \n",
            "ğŸ” Running research for ' Gen AI åœ¨æœåŠ¡ä¸­çš„å®é™…æˆæœ'...\n",
            "INFO:     [07:10:27] âœ… Added source url to research: https://www.thomsonreuters.com/en/reports/2024-generative-ai-in-professional-services.html\n",
            "\n",
            "INFO:     [07:10:27] âœ… Added source url to research: https://www.mckinsey.com/~/media/mckinsey/business+functions/quantumblack/our+insights/the+state+of+ai/2024/the-state-of-ai-in-early-2024-final.pdf\n",
            "\n",
            "INFO:     [07:10:27] âœ… Added source url to research: https://www.thomsonreuters.com/en-us/posts/technology/genai-professional-services-2024/\n",
            "\n",
            "INFO:     [07:10:27] âœ… Added source url to research: https://www.gartner.com/en/articles/3-bold-and-actionable-predictions-for-the-future-of-genai\n",
            "\n",
            "INFO:     [07:10:27] âœ… Added source url to research: https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai\n",
            "\n",
            "INFO:     [07:10:27] ğŸ¤” Researching for relevant information across multiple sources...\n",
            "\n",
            "INFO:     [07:10:27] ğŸŒ Scraping content from 5 URLs...\n",
            "INFO:     [07:10:28] ğŸ“„ Scraped 4 pages of content\n",
            "INFO:     [07:10:28] ğŸ–¼ï¸ Selected 2 new images from 2 total images\n",
            "INFO:     [07:10:28] ğŸŒ Scraping complete\n",
            "INFO:     [07:10:28] ğŸ“š Getting relevant content based on query: Generative AI impact on business services 2024...\n",
            "INFO:     [07:10:28] âœ… Added source url to research: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/enterprise-technologys-next-chapter-four-gen-ai-shifts-that-will-reshape-business-technology\n",
            "\n",
            "INFO:     [07:10:28] âœ… Added source url to research: https://www.mckinsey.com/capabilities/operations/our-insights/gen-ai-in-corporate-functions-looking-beyond-efficiency-gains\n",
            "\n",
            "INFO:     [07:10:29] âœ… Added source url to research: https://www.weforum.org/stories/2024/11/generative-ai-work-implementation-scaling/\n",
            "\n",
            "INFO:     [07:10:29] âœ… Added source url to research: https://www.deloitte.com/global/en/what-we-do/capabilities/gen-ai-services.html\n",
            "\n",
            "INFO:     [07:10:29] âœ… Added source url to research: https://cloud.google.com/transform/101-real-world-generative-ai-use-cases-from-industry-leaders\n",
            "\n",
            "INFO:     [07:10:29] ğŸ¤” Researching for relevant information across multiple sources...\n",
            "\n",
            "INFO:     [07:10:29] ğŸŒ Scraping content from 5 URLs...\n",
            "INFO:     [07:10:30] ğŸ“„ Scraped 4 pages of content\n",
            "INFO:     [07:10:30] ğŸ–¼ï¸ Selected 4 new images from 4 total images\n",
            "INFO:     [07:10:30] ğŸŒ Scraping complete\n",
            "INFO:     [07:10:30] ğŸ“š Getting relevant content based on query:  Gen AI åœ¨æœåŠ¡ä¸­çš„å®é™…æˆæœ...\n",
            "INFO:     [07:10:30] âœ… Added source url to research: https://venturebeat.com/ai/mckinsey-says-about-half-of-its-employees-are-using-generative-ai/\n",
            "\n",
            "INFO:     [07:10:30] âœ… Added source url to research: https://www.technologyreview.com/2023/07/18/1076423/the-great-acceleration-cio-perspectives-on-generative-ai/\n",
            "\n",
            "INFO:     [07:10:30] âœ… Added source url to research: https://venturebeat.com/ai/mckinsey-gen-ai-adoption-rockets-generates-value-for-enterprises/\n",
            "\n",
            "INFO:     [07:10:30] ğŸ¤” Researching for relevant information across multiple sources...\n",
            "\n",
            "INFO:     [07:10:30] ğŸŒ Scraping content from 3 URLs...\n",
            "INFO:     [07:10:31] ğŸ“„ Scraped 3 pages of content\n",
            "INFO:     [07:10:31] ğŸ–¼ï¸ Selected 0 new images from 0 total images\n",
            "INFO:     [07:10:31] ğŸŒ Scraping complete\n",
            "INFO:     [07:10:31] ğŸ“š Getting relevant content based on query: McKinsey insights on Gen AI in enterprise technology...\n",
            "INFO:     [07:10:31] âœ… Added source url to research: https://www.mckinsey.com/capabilities/operations/our-insights/generative-ai-in-operations\n",
            "\n",
            "INFO:     [07:10:31] âœ… Added source url to research: https://www.gartner.com/en/articles/generative-ai-use-cases\n",
            "\n",
            "INFO:     [07:10:31] âœ… Added source url to research: https://www.databricks.com/blog/how-real-world-enterprises-are-leveraging-generative-ai\n",
            "\n",
            "INFO:     [07:10:31] âœ… Added source url to research: https://cloud.google.com/transform/where-gen-ai-is-impacting-industries-in-2024\n",
            "\n",
            "INFO:     [07:10:31] ğŸ¤” Researching for relevant information across multiple sources...\n",
            "\n",
            "INFO:     [07:10:31] ğŸŒ Scraping content from 4 URLs...\n",
            "INFO:     [07:10:32] ğŸ“„ Scraped 4 pages of content\n",
            "INFO:     [07:10:32] ğŸ–¼ï¸ Selected 0 new images from 0 total images\n",
            "INFO:     [07:10:32] ğŸŒ Scraping complete\n",
            "INFO:     [07:10:32] ğŸ“š Getting relevant content based on query: Real results of Gen AI in service industries...\n",
            "INFO:     [07:10:32] âœ… Added source url to research: https://www.mckinsey.com/capabilities/operations/our-insights/from-promising-to-productive-real-results-from-gen-ai-in-services\n",
            "\n",
            "INFO:     [07:10:32] âœ… Added source url to research: https://aws.amazon.com/blogs/machine-learning/generative-ai-powered-technology-operations/\n",
            "\n",
            "INFO:     [07:10:32] âœ… Added source url to research: https://www.ey.com/en_us/insights/ai/productivity-potential-gen-ai\n",
            "\n",
            "INFO:     [07:10:32] âœ… Added source url to research: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier\n",
            "\n",
            "INFO:     [07:10:32] ğŸ¤” Researching for relevant information across multiple sources...\n",
            "\n",
            "INFO:     [07:10:33] ğŸŒ Scraping content from 4 URLs...\n",
            "INFO:     [07:10:35] ğŸ“„ Scraped 4 pages of content\n",
            "INFO:     [07:10:35] ğŸ–¼ï¸ Selected 4 new images from 5 total images\n",
            "INFO:     [07:10:35] ğŸŒ Scraping complete\n",
            "INFO:     [07:10:35] ğŸ“š Getting relevant content based on query: Generative AI productivity boost in operations...\n",
            "INFO:     [07:11:24] ğŸ“ƒ Source: https://www.thomsonreuters.com/en-us/posts/technology/genai-professional-services-2024/\n",
            "Title: GenAI in professional services: The future is automated - Thomson Reuters Institute\n",
            "Content: Further, among those respondents who said they believe GenAI should be applied to their work, many focused particularly on the business impact of the technology. Tax industry respondents, for example, pointed to increasing efficiency and productivity, streamlining work processes, and improving quality and accuracy of work. Legal industry respondents, meanwhile, pointed to GenAIâ€™s potential for cost savings, its ability to allow professionals to spend more time on high-value tasks, and its capacity to aid in quality control checks.\n",
            "Overall, the 2024 Generative AI in Professional Services report illustrates how the professional services market is reacting quickly to a potentially disruptive force in GenAI. Although its true impact may seem a proposition for far in the future, planning for its impact now is critical.\n",
            "\n",
            "Source: https://www.thomsonreuters.com/en/reports/2024-generative-ai-in-professional-services.html\n",
            "Title: 2024 generative AI in professional services report | Thomson Reuters\n",
            "Content: Special Report 2024 generative AI in professional services\n",
            "2024 generative AI in professional services\n",
            "2024 generative AI in professional services\n",
            "2024 generative AI in professional services\n",
            "2024 generative AI in professional services\n",
            "\n",
            "Source: https://www.thomsonreuters.com/en-us/posts/technology/genai-professional-services-2024/\n",
            "Title: GenAI in professional services: The future is automated - Thomson Reuters Institute\n",
            "Content: quality control checks. Overall, the 2024 Generative AI in Professional Services report illustrates how the professional services market is reacting quickly to a potentially disruptive force in GenAI. Although its true impact may seem a proposition for far in the future, planning for its impact now is critical. As our research shows, those proactive organizations that have already begun to explore how GenAI will change the future of their work will gain a distinctive advantage of those organizations without such inclination or planning. You can download the Thomson Reuters Instituteâ€™s recently published 2024 Generative AI in Professional Services report here. Facebook Twitter Linkedin Email AI & Future TechnologiesCorporate Law DepartmentsCorporatesGenAI ReportsGenerative AILegal TechnologyProfessional DevelopmentService ProfessionalsTalent DevelopmentTalent ManagementTax Tech & Innovation Solutions Thomson Reuters Advisory Services We partner with firms to guide, create and\n",
            "\n",
            "Source: https://www.thomsonreuters.com/en-us/posts/technology/genai-professional-services-2024/\n",
            "Title: GenAI in professional services: The future is automated - Thomson Reuters Institute\n",
            "Content: quality control checks. Overall, the 2024 Generative AI in Professional Services report illustrates how the professional services market is reacting quickly to a potentially disruptive force in GenAI. Although its true impact may seem a proposition for far in the future, planning for its impact now is critical. As our research shows, those proactive organizations that have already begun to explore how GenAI will change the future of their work will gain a distinctive advantage of those organizations without such inclination or planning. You can download the Thomson Reuters Instituteâ€™s recently published 2024 Generative AI in Professional Services report here. Facebook Twitter Linkedin Email AI & Future TechnologiesCorporate Law DepartmentsCorporatesGenAI ReportsGenerative AILegal TechnologyProfessional DevelopmentService ProfessionalsTalent DevelopmentTalent ManagementTax Tech & Innovation Solutions Thomson Reuters Advisory Services We partner with firms to guide, create and\n",
            "\n",
            "Source: https://www.thomsonreuters.com/en-us/posts/technology/genai-professional-services-2024/\n",
            "Title: GenAI in professional services: The future is automated - Thomson Reuters Institute\n",
            "Content: quality control checks. Overall, the 2024 Generative AI in Professional Services report illustrates how the professional services market is reacting quickly to a potentially disruptive force in GenAI. Although its true impact may seem a proposition for far in the future, planning for its impact now is critical. As our research shows, those proactive organizations that have already begun to explore how GenAI will change the future of their work will gain a distinctive advantage of those organizations without such inclination or planning. You can download the Thomson Reuters Instituteâ€™s recently published 2024 Generative AI in Professional Services report here. Facebook Twitter Linkedin Email AI & Future TechnologiesCorporate Law DepartmentsCorporatesGenAI ReportsGenerative AILegal TechnologyProfessional DevelopmentService ProfessionalsTalent DevelopmentTalent ManagementTax Tech & Innovation Solutions Thomson Reuters Advisory Services We partner with firms to guide, create and\n",
            "\n",
            "Source: https://www.thomsonreuters.com/en/reports/2024-generative-ai-in-professional-services.html\n",
            "Title: 2024 generative AI in professional services report | Thomson Reuters\n",
            "Content: Special Report 2024 generative AI in professional services Perceptions, usage, and impact on the future of work Generative AI (GenAI), once a futuristic concept, is here and reshaping the professional landscape across service industries like legal, tax and accounting, risk and fraud, and government. Since its debut in late 2022, platforms like ChatGPT and advancements like GPT-4 have demonstrated disruptive potential, enabling the rapid creation of high-quality content with heightened accuracy. While adoption isn't yet widespread, more than half of professionals believe they should use GenAI in their daily work â€” and theyâ€™re already planning for the specialized tools that will create this reality. In this report, we explore how these professionals perceive the use of generative AI in their workplace, how and to what level they are using and integrating it into their processes, and perceptions of the future of work in an environment in which generative AI has made its presence felt.\n",
            "\n",
            "Source: https://www.thomsonreuters.com/en/reports/2024-generative-ai-in-professional-services.html\n",
            "Title: 2024 generative AI in professional services report | Thomson Reuters\n",
            "Content: Special Report 2024 generative AI in professional services Perceptions, usage, and impact on the future of work Generative AI (GenAI), once a futuristic concept, is here and reshaping the professional landscape across service industries like legal, tax and accounting, risk and fraud, and government. Since its debut in late 2022, platforms like ChatGPT and advancements like GPT-4 have demonstrated disruptive potential, enabling the rapid creation of high-quality content with heightened accuracy. While adoption isn't yet widespread, more than half of professionals believe they should use GenAI in their daily work â€” and theyâ€™re already planning for the specialized tools that will create this reality. In this report, we explore how these professionals perceive the use of generative AI in their workplace, how and to what level they are using and integrating it into their processes, and perceptions of the future of work in an environment in which generative AI has made its presence felt.\n",
            "\n",
            "Source: https://www.thomsonreuters.com/en/reports/2024-generative-ai-in-professional-services.html\n",
            "Title: 2024 generative AI in professional services report | Thomson Reuters\n",
            "Content: Special Report 2024 generative AI in professional services Perceptions, usage, and impact on the future of work Generative AI (GenAI), once a futuristic concept, is here and reshaping the professional landscape across service industries like legal, tax and accounting, risk and fraud, and government. Since its debut in late 2022, platforms like ChatGPT and advancements like GPT-4 have demonstrated disruptive potential, enabling the rapid creation of high-quality content with heightened accuracy. While adoption isn't yet widespread, more than half of professionals believe they should use GenAI in their daily work â€” and theyâ€™re already planning for the specialized tools that will create this reality. In this report, we explore how these professionals perceive the use of generative AI in their workplace, how and to what level they are using and integrating it into their processes, and perceptions of the future of work in an environment in which generative AI has made its presence felt.\n",
            "\n",
            "Source: https://www.thomsonreuters.com/en/reports/2024-generative-ai-in-professional-services.html\n",
            "Title: 2024 generative AI in professional services report | Thomson Reuters\n",
            "Content: Special Report 2024 generative AI in professional services Perceptions, usage, and impact on the future of work Generative AI (GenAI), once a futuristic concept, is here and reshaping the professional landscape across service industries like legal, tax and accounting, risk and fraud, and government. Since its debut in late 2022, platforms like ChatGPT and advancements like GPT-4 have demonstrated disruptive potential, enabling the rapid creation of high-quality content with heightened accuracy. While adoption isn't yet widespread, more than half of professionals believe they should use GenAI in their daily work â€” and theyâ€™re already planning for the specialized tools that will create this reality. In this report, we explore how these professionals perceive the use of generative AI in their workplace, how and to what level they are using and integrating it into their processes, and perceptions of the future of work in an environment in which generative AI has made its presence felt.\n",
            "\n",
            "Source: https://www.thomsonreuters.com/en/reports/2024-generative-ai-in-professional-services.html\n",
            "Title: 2024 generative AI in professional services report | Thomson Reuters\n",
            "Content: Special Report 2024 generative AI in professional services Perceptions, usage, and impact on the future of work Generative AI (GenAI), once a futuristic concept, is here and reshaping the professional landscape across service industries like legal, tax and accounting, risk and fraud, and government. Since its debut in late 2022, platforms like ChatGPT and advancements like GPT-4 have demonstrated disruptive potential, enabling the rapid creation of high-quality content with heightened accuracy. While adoption isn't yet widespread, more than half of professionals believe they should use GenAI in their daily work â€” and theyâ€™re already planning for the specialized tools that will create this reality. In this report, we explore how these professionals perceive the use of generative AI in their workplace, how and to what level they are using and integrating it into their processes, and perceptions of the future of work in an environment in which generative AI has made its presence felt.\n",
            "\n",
            "INFO:     [07:12:39] ğŸ“ƒ Source: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier\n",
            "Title: Economic potential of generative AI | McKinsey\n",
            "Content: with workers, augmenting their work in ways that accelerate their productivity. Its ability to rapidly digest mountains of data and draw conclusions from it enables the technology to offer insights and options that can dramatically enhance knowledge work. This can significantly speed up the process of developing a product and allow employees to devote more time to higher-impact tasks. Following are four examples of how generative AI could produce operational benefits in a handful of use cases across the business functions that could deliver a majority of the potential value we identified in our analysis of 63 generative AI use cases. In the first two examples, it serves as a virtual expert, while in the following two, it lends a hand as a virtual collaborator. Customer operations: Improving customer and agent experiences Generative AI has the potential to revolutionize the entire customer operations function, improving the customer experience and agent productivity through digital\n",
            "\n",
            "Source: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier\n",
            "Title: Economic potential of generative AI | McKinsey\n",
            "Content: with workers, augmenting their work in ways that accelerate their productivity. Its ability to rapidly digest mountains of data and draw conclusions from it enables the technology to offer insights and options that can dramatically enhance knowledge work. This can significantly speed up the process of developing a product and allow employees to devote more time to higher-impact tasks. Following are four examples of how generative AI could produce operational benefits in a handful of use cases across the business functions that could deliver a majority of the potential value we identified in our analysis of 63 generative AI use cases. In the first two examples, it serves as a virtual expert, while in the following two, it lends a hand as a virtual collaborator. Customer operations: Improving customer and agent experiences Generative AI has the potential to revolutionize the entire customer operations function, improving the customer experience and agent productivity through digital\n",
            "\n",
            "Source: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier\n",
            "Title: Economic potential of generative AI | McKinsey\n",
            "Content: Generative AI can substantially increase labor productivity across the economy, but that will require investments to support workers as they shift work activities or change jobs. Generative AI could enable labor productivity growth of 0.1 to 0.6 percent annually through 2040, depending on the rate of technology adoption and redeployment of worker time into other activities. Combining generative AI with all other technologies, work automation could add 0.5 to 3.4 percentage points annually to productivity growth. However, workers will need support in learning new skills, and some will change occupations. If worker transitions and other risks can be managed, generative AI could contribute substantively to economic growth and support a more sustainable, inclusive world.\n",
            "\n",
            "Source: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier\n",
            "Title: Economic potential of generative AI | McKinsey\n",
            "Content: 1Erik Brynjolfsson, Danielle Li, and Lindsey R. Raymond, Generative AI at work, National Bureau of Economic Research working paper number 31161, April 2023.\n",
            "Erik Brynjolfsson, Danielle Li, and Lindsey R. Raymond, Generative AI at work, National Bureau of Economic Research working paper number 31161, April 2023.\n",
            "Erik Brynjolfsson, Danielle Li, and Lindsey R. Raymond, Generative AI at work, National Bureau of Economic Research working paper number 31161, April 2023.\n",
            "Erik Brynjolfsson, Danielle Li, and Lindsey R. Raymond, Generative AI at work, National Bureau of Economic Research working paper number 31161, April 2023.\n",
            "The following are examples of the operational improvements generative AI can have for specific use cases:\n",
            "\n",
            "Source: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier\n",
            "Title: Economic potential of generative AI | McKinsey\n",
            "Content: We estimate that applying generative AI to customer care functions could increase productivity at a value ranging from 30 to 45 percent of current function costs. Our analysis captures only the direct impact generative AI might have on the productivity of customer operations. It does not account for potential knock-on effects the technology may have on customer satisfaction and retention arising from an improved experience, including better understanding of the customerÃ¢Â€Â™s context that can assist human agents in providing more personalized help and recommendations. Marketing and sales: Boosting personalization, content creation, and sales productivity Generative AI has taken hold rapidly in marketing and sales functions, in which text-based communications and personalization at scale are driving forces. The technology can create personalized messages tailored to individual customer interests, preferences, and behaviors, as well as do tasks such as producing first drafts of brand\n",
            "\n",
            "Source: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier\n",
            "Title: Economic potential of generative AI | McKinsey\n",
            "Content: We estimate that applying generative AI to customer care functions could increase productivity at a value ranging from 30 to 45 percent of current function costs. Our analysis captures only the direct impact generative AI might have on the productivity of customer operations. It does not account for potential knock-on effects the technology may have on customer satisfaction and retention arising from an improved experience, including better understanding of the customerÃ¢Â€Â™s context that can assist human agents in providing more personalized help and recommendations. Marketing and sales: Boosting personalization, content creation, and sales productivity Generative AI has taken hold rapidly in marketing and sales functions, in which text-based communications and personalization at scale are driving forces. The technology can create personalized messages tailored to individual customer interests, preferences, and behaviors, as well as do tasks such as producing first drafts of brand\n",
            "\n",
            "Source: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier\n",
            "Title: Economic potential of generative AI | McKinsey\n",
            "Content: We estimate that applying generative AI to customer care functions could increase productivity at a value ranging from 30 to 45 percent of current function costs. Our analysis captures only the direct impact generative AI might have on the productivity of customer operations. It does not account for potential knock-on effects the technology may have on customer satisfaction and retention arising from an improved experience, including better understanding of the customerÃ¢Â€Â™s context that can assist human agents in providing more personalized help and recommendations. Marketing and sales: Boosting personalization, content creation, and sales productivity Generative AI has taken hold rapidly in marketing and sales functions, in which text-based communications and personalization at scale are driving forces. The technology can create personalized messages tailored to individual customer interests, preferences, and behaviors, as well as do tasks such as producing first drafts of brand\n",
            "\n",
            "Source: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier\n",
            "Title: Economic potential of generative AI | McKinsey\n",
            "Content: Generative AI is poised to unleash the next wave of productivity. We take a first look at where business value could accrue and the potential impacts on the workforce. Ã‚ The economic potential of generative AI: The next productivity frontier (68 pages) AI has permeated our lives incrementally, through everything from the tech powering our smartphones to autonomous-driving features on cars to the tools retailers use to surprise and delight consumers. As a result, its progress has been almost imperceptible. Clear milestones, such as when AlphaGo, an AI-based program developed by DeepMind, defeated a world champion Go player in 2016, were celebrated but then quickly faded from the publicÃ¢Â€Â™s consciousness. Generative AI applications such as ChatGPT, GitHub Copilot, Stable Diffusion, and others have captured the imagination of people around the world in a way AlphaGo did not, thanks to their broad utilityÃ¢Â€Â”almost anyone can use them to communicate and createÃ¢Â€Â”and preternatural ability\n",
            "\n",
            "Source: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier\n",
            "Title: Economic potential of generative AI | McKinsey\n",
            "Content: Generative AI is poised to unleash the next wave of productivity. We take a first look at where business value could accrue and the potential impacts on the workforce. Ã‚ The economic potential of generative AI: The next productivity frontier (68 pages) AI has permeated our lives incrementally, through everything from the tech powering our smartphones to autonomous-driving features on cars to the tools retailers use to surprise and delight consumers. As a result, its progress has been almost imperceptible. Clear milestones, such as when AlphaGo, an AI-based program developed by DeepMind, defeated a world champion Go player in 2016, were celebrated but then quickly faded from the publicÃ¢Â€Â™s consciousness. Generative AI applications such as ChatGPT, GitHub Copilot, Stable Diffusion, and others have captured the imagination of people around the world in a way AlphaGo did not, thanks to their broad utilityÃ¢Â€Â”almost anyone can use them to communicate and createÃ¢Â€Â”and preternatural ability\n",
            "\n",
            "Source: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier\n",
            "Title: Economic potential of generative AI | McKinsey\n",
            "Content: generative AI can enhance quality assurance and coaching by gathering insights from customer conversations, determining what could be done better, and coaching agents. We estimate that applying generative AI to customer care functions could increase productivity at a value ranging from 30 to 45 percent of current function costs. Our analysis captures only the direct impact generative AI might have on the productivity of customer operations. It does not account for potential knock-on effects the technology may have on customer satisfaction and retention arising from an improved experience, including better understanding of the customerÃ¢Â€Â™s context that can assist human agents in providing more personalized help and recommendations. Marketing and sales: Boosting personalization, content creation, and sales productivity Generative AI has taken hold rapidly in marketing and sales functions, in which text-based communications and personalization at scale are driving forces. The technology\n",
            "\n",
            "INFO:     [07:13:44] ğŸ“ƒ Source: https://venturebeat.com/ai/mckinsey-gen-ai-adoption-rockets-generates-value-for-enterprises/\n",
            "Title: McKinsey: Gen AI adoption rockets, generates value for enterprises | VentureBeat\n",
            "Content: McKinsey: Gen AI adoption rockets, generates value for enterprises\n",
            "McKinsey: Gen AI adoption rockets, generates value for enterprises\n",
            "May 30, 2024 4:50 PM\n",
            "Share on Facebook Share on X Share on LinkedIn\n",
            "Share on Facebook\n",
            "Share on X\n",
            "Share on LinkedIn\n",
            "\n",
            "Source: https://venturebeat.com/ai/mckinsey-gen-ai-adoption-rockets-generates-value-for-enterprises/\n",
            "Title: McKinsey: Gen AI adoption rockets, generates value for enterprises | VentureBeat\n",
            "Content: McKinsey: Gen AI adoption rockets, generates value for enterprises Taryn Plumb@taryn_plumb May 30, 2024 4:50 PM Share on Facebook Share on X Share on LinkedIn VentureBeat/Midjourney Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More Organizations are in a wild race to adopt generative AI â€” it is one of the most significant technological innovations in a generation (or multiple generations). In fact, just a year-and-a-half after ChatGPT was announced â€” changing the world as we know it â€” 65% of organizations are regularly using AI, according to a new report from consulting firm McKinsey. This is nearly double the percentage from the firmâ€™s previous McKinsey Global Survey only 10 months ago. Looking ahead, expectations are high: The majority of respondents predict that gen AI will lead to â€œsignificant or disruptiveâ€ change in their industries. â€œIn 2024, gen AI is no longer a novelty,â€ said Alex Singla, senior\n",
            "\n",
            "Source: https://venturebeat.com/ai/mckinsey-says-about-half-of-its-employees-are-using-generative-ai/\n",
            "Title: McKinsey says 'about half' of its employees are using generative AI | VentureBeat\n",
            "Content: McKinsey says â€˜about halfâ€™ of its employees are using generative AI Carl Franzen@carlfranzen June 6, 2023 9:45 AM Share on Facebook Share on X Share on LinkedIn Credit: VentureBeat made with Midjourney Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More McKinsey and Company, the global consulting firm with more than 30,000 employees in 67 countries, is embracing new generative AI tools in a major way: Nearly 50% of the firmâ€™s workforce is using ChatGPT and similar technology. â€œAbout half of [our employees] are using those services with McKinseyâ€™s permission,â€ said Ben Ellencweig, senior partner and leader of alliances and acquisitions at QuantumBlack, the firmâ€™s artificial intelligence consulting arm, during a media event at McKinseyâ€™s New York Experience Studio on Tuesday. Ellencweig emphasized that McKinsey had guardrails for employees using generative AI, including â€œguidelines and principlesâ€ about what\n",
            "\n",
            "Source: https://venturebeat.com/ai/mckinsey-gen-ai-adoption-rockets-generates-value-for-enterprises/\n",
            "Title: McKinsey: Gen AI adoption rockets, generates value for enterprises | VentureBeat\n",
            "Content: cost reduction in human resources. On average, respondents also reported that their organizations required one to four months to get gen AI into production. Also, workers at all levels are growing increasingly comfortable with AI tools not just at work, but at home. Today, they are using gen AI across their professional and personal lives. Surprisingly, 41% of C-level execs report using gen AI regularly at work. â€œThe pace of innovation, the evolution of new companies and capabilities and the wave of investment have been remarkable,â€ said McKinsey associate partner Bryce Hall. â€œNow weâ€™re seeing how leading companies are capturing business value from these often-dazzling AI and gen AI capabilities.â€ Takers, shapers and makers McKinsey identifies three archetypes for implementing gen AI: â€œtakersâ€ who use off-the-shelf tools; â€œshapersâ€ who customize those publicly available tools; and â€œmakersâ€ who develop their own models from scratch. Interestingly, the survey found that most\n",
            "\n",
            "Source: https://venturebeat.com/ai/mckinsey-gen-ai-adoption-rockets-generates-value-for-enterprises/\n",
            "Title: McKinsey: Gen AI adoption rockets, generates value for enterprises | VentureBeat\n",
            "Content: cost reduction in human resources. On average, respondents also reported that their organizations required one to four months to get gen AI into production. Also, workers at all levels are growing increasingly comfortable with AI tools not just at work, but at home. Today, they are using gen AI across their professional and personal lives. Surprisingly, 41% of C-level execs report using gen AI regularly at work. â€œThe pace of innovation, the evolution of new companies and capabilities and the wave of investment have been remarkable,â€ said McKinsey associate partner Bryce Hall. â€œNow weâ€™re seeing how leading companies are capturing business value from these often-dazzling AI and gen AI capabilities.â€ Takers, shapers and makers McKinsey identifies three archetypes for implementing gen AI: â€œtakersâ€ who use off-the-shelf tools; â€œshapersâ€ who customize those publicly available tools; and â€œmakersâ€ who develop their own models from scratch. Interestingly, the survey found that most\n",
            "\n",
            "Source: https://venturebeat.com/ai/mckinsey-gen-ai-adoption-rockets-generates-value-for-enterprises/\n",
            "Title: McKinsey: Gen AI adoption rockets, generates value for enterprises | VentureBeat\n",
            "Content: â€œThe pace of innovation, the evolution of new companies and capabilities and the wave of investment have been remarkable,â€ said McKinsey associate partner Bryce Hall. â€œNow weâ€™re seeing how leading companies are capturing business value from these often-dazzling AI and gen AI capabilities.â€\n",
            "Takers, shapers and makers\n",
            "McKinsey identifies three archetypes for implementing gen AI: â€œtakersâ€ who use off-the-shelf tools; â€œshapersâ€ who customize those publicly available tools; and â€œmakersâ€ who develop their own models from scratch.\n",
            "Interestingly, the survey found that most organizations are half-and-half: Roughly 50% of gen AI uses were from off-the-shelf tools, while the other were â€œsignificantly customizedâ€ or built from scratch. This is across technology, media and telecommunications, consumer goods and retail, financial services and business and legal and professional services.\n",
            "\n",
            "Source: https://venturebeat.com/ai/mckinsey-gen-ai-adoption-rockets-generates-value-for-enterprises/\n",
            "Title: McKinsey: Gen AI adoption rockets, generates value for enterprises | VentureBeat\n",
            "Content: change in their industries. â€œIn 2024, gen AI is no longer a novelty,â€ said Alex Singla, senior partner and global co-leader of QuantumBlack, AI by McKinsey. â€œThe technologyâ€™s potential is no longer in question. And while most organizations are still in the early stages of their journeys with gen AI, we are beginning to get a picture of what works and what doesnâ€™t in implementing â€” and generating actual value with â€” the technology.â€ AI investment increasing at a rapid pace Half of the respondents to the survey said their organizations have adopted AI in two or more business functions, and 67% expect AI investment to increase in the next three years. The biggest increase in adoption is in professional services, and gen AI is (today at least) most often being used in marketing and sales (for content, personalization and sales leads); product and service development (for design development, scientific literature and research review); and IT (for help desk chatbots, data management,\n",
            "\n",
            "Source: https://venturebeat.com/ai/mckinsey-says-about-half-of-its-employees-are-using-generative-ai/\n",
            "Title: McKinsey says 'about half' of its employees are using generative AI | VentureBeat\n",
            "Content: Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More\n",
            "Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More\n",
            "McKinsey and Company, the global consulting firm with more than 30,000 employees in 67 countries, is embracing new generative AI tools in a major way: Nearly 50% of the firmâ€™s workforce is using ChatGPT and similar technology.\n",
            "â€œAbout half of [our employees] are using those services with McKinseyâ€™s permission,â€ said Ben Ellencweig, senior partner and leader of alliances and acquisitions at QuantumBlack, the firmâ€™s artificial intelligence consulting arm, during a media event at McKinseyâ€™s New York Experience Studio on Tuesday.\n",
            "Ellencweig emphasized that McKinsey had guardrails for employees using generative AI, including â€œguidelines and principlesâ€ about what information the workers could input into these services.\n",
            "\n",
            "Source: https://venturebeat.com/ai/mckinsey-says-about-half-of-its-employees-are-using-generative-ai/\n",
            "Title: McKinsey says 'about half' of its employees are using generative AI | VentureBeat\n",
            "Content: McKinsey says â€˜about halfâ€™ of its employees are using generative AI\n",
            "McKinsey says â€˜about halfâ€™ of its employees are using generative AI\n",
            "June 6, 2023 9:45 AM\n",
            "Share on Facebook Share on X Share on LinkedIn\n",
            "Share on Facebook\n",
            "Share on X\n",
            "Share on LinkedIn\n",
            "Credit: VentureBeat made with Midjourney\n",
            "Credit: VentureBeat made with Midjourney\n",
            "Credit: VentureBeat made with Midjourney\n",
            "\n",
            "Source: https://venturebeat.com/ai/mckinsey-gen-ai-adoption-rockets-generates-value-for-enterprises/\n",
            "Title: McKinsey: Gen AI adoption rockets, generates value for enterprises | VentureBeat\n",
            "Content: spine and brain of the enterprise of the future will rely on a well-orchestrated mix of multiple foundational models â€” both off-the-shelf solutions and tools that have been finely tuned to the enterpriseâ€™s specific needs.â€ Challenges with data, explainability, security Still, organizations arenâ€™t blind to the inherent risks in AI: In fact, 44% of respondents say their organization has already experienced negative consequences from gen AI use. This has typically been inaccuracy in outputs, cybersecurity and lack of explainability. Other issues include incorrect use of AI and data privacy, bias or intellectual property (IP) infringement. Additionally, â€œhigh performersâ€ identified by McKinsey are specifically experiencing challenges with data â€” they report insufficient amounts of training data, a struggle to define processes for data governance and quick integration of data. While they recognize these challenges, though, just 18% of respondents said their employers had an enterprise-wide\n",
            "\n",
            "INFO:     [07:23:17] ğŸ“ƒ Source: https://www.deloitte.com/global/en/what-we-do/capabilities/gen-ai-services.html\n",
            "Title: Generative AI services\n",
            "Content: Operationalize legal and risk management practices & controls Optimize GenAI with managed services Maximize performance of models and platforms with leading AI operations practices and use of managed services Find out more Optimize GenAI with managed services Maximize performance of models and platforms with leading AI operations practices and use of managed services Client stories Investing in a more authentic customer experience Rakuten Securities, Deloitte Japan, and NVIDIA collaborate to build an innovative AI avatar that delivers an enhanced digital customer experience. Learn more Bringing AI to the forefront of a tech-driven food revolution Compass Group Australia and Deloitte Australia launch an AI-enabled system for improving nutrition among older adults. Learn more It's not about the tool. Itâ€™s about the toolâ€™s capabilities. A state government program explores GenAIâ€™s potential to augment a digital transformation and help improve productivity. Learn more A new day for the\n",
            "\n",
            "Source: https://www.deloitte.com/global/en/what-we-do/capabilities/gen-ai-services.html\n",
            "Title: Generative AI services\n",
            "Content: Operationalize legal and risk management practices & controls Optimize GenAI with managed services Maximize performance of models and platforms with leading AI operations practices and use of managed services Find out more Optimize GenAI with managed services Maximize performance of models and platforms with leading AI operations practices and use of managed services Client stories Investing in a more authentic customer experience Rakuten Securities, Deloitte Japan, and NVIDIA collaborate to build an innovative AI avatar that delivers an enhanced digital customer experience. Learn more Bringing AI to the forefront of a tech-driven food revolution Compass Group Australia and Deloitte Australia launch an AI-enabled system for improving nutrition among older adults. Learn more It's not about the tool. Itâ€™s about the toolâ€™s capabilities. A state government program explores GenAIâ€™s potential to augment a digital transformation and help improve productivity. Learn more A new day for the\n",
            "\n",
            "Source: https://cloud.google.com/transform/101-real-world-generative-ai-use-cases-from-industry-leaders\n",
            "Title: 185 real-world gen AI use cases from the world's leading organizations | Google Cloud Blog\n",
            "Content: of months, organizations have gone from AI helping answer questions, to AI making predictions, to generative AI agents. What makes AI agents unique is that they can take actions to achieve specific goals, whether thatâ€™s guiding a shopper to the perfect pair of shoes, helping an employee looking for the right health benefits, or supporting nursing staff with smoother patient hand-offs during shifts changes.In our work with customers, we keep hearing that their teams are increasingly focused on improving productivity, automating processes, and modernizing the customer experience. These aims are now being achieved through the AI agents theyâ€™re developing in six key areas: customer service; employee empowerment; code creation; data analysis; cybersecurity; and creative ideation and production.Hundreds of Google Cloud customers have now put AI agents and gen-AI solutions into production throughout their businesses and the world â€” with many seeing a tangible return on investment. They have\n",
            "\n",
            "Source: https://cloud.google.com/transform/101-real-world-generative-ai-use-cases-from-industry-leaders\n",
            "Title: 185 real-world gen AI use cases from the world's leading organizations | Google Cloud Blog\n",
            "Content: of months, organizations have gone from AI helping answer questions, to AI making predictions, to generative AI agents. What makes AI agents unique is that they can take actions to achieve specific goals, whether thatâ€™s guiding a shopper to the perfect pair of shoes, helping an employee looking for the right health benefits, or supporting nursing staff with smoother patient hand-offs during shifts changes.In our work with customers, we keep hearing that their teams are increasingly focused on improving productivity, automating processes, and modernizing the customer experience. These aims are now being achieved through the AI agents theyâ€™re developing in six key areas: customer service; employee empowerment; code creation; data analysis; cybersecurity; and creative ideation and production.Hundreds of Google Cloud customers have now put AI agents and gen-AI solutions into production throughout their businesses and the world â€” with many seeing a tangible return on investment. They have\n",
            "\n",
            "Source: https://cloud.google.com/transform/101-real-world-generative-ai-use-cases-from-industry-leaders\n",
            "Title: 185 real-world gen AI use cases from the world's leading organizations | Google Cloud Blog\n",
            "Content: In a matter of months, organizations have gone from AI helping answer questions, to AI making predictions, to generative AI agents. What makes AI agents unique is that they can take actions to achieve specific goals, whether thatâ€™s guiding a shopper to the perfect pair of shoes, helping an employee looking for the right health benefits, or supporting nursing staff with smoother patient hand-offs during shifts changes.\n",
            "In our work with customers, we keep hearing that their teams are increasingly focused on improving productivity, automating processes, and modernizing the customer experience. These aims are now being achieved through the AI agents theyâ€™re developing in six key areas: customer service; employee empowerment; code creation; data analysis; cybersecurity; and creative ideation and production.\n",
            "\n",
            "Source: https://www.deloitte.com/global/en/what-we-do/capabilities/gen-ai-services.html\n",
            "Title: Generative AI services\n",
            "Content: to stay ahead of evolving labor market needs Find out more GenAI training and upskilling Build new talent solutions to stay ahead of evolving labor market needs GenAI governance and risk management Operationalize legal and risk management practices & controls Find out more GenAI governance and risk management Operationalize legal and risk management practices & controls Optimize GenAI with managed services Maximize performance of models and platforms with leading AI operations practices and use of managed services Find out more Optimize GenAI with managed services Maximize performance of models and platforms with leading AI operations practices and use of managed services Client stories Investing in a more authentic customer experience Rakuten Securities, Deloitte Japan, and NVIDIA collaborate to build an innovative AI avatar that delivers an enhanced digital customer experience. Learn more Bringing AI to the forefront of a tech-driven food revolution Compass Group Australia and\n",
            "\n",
            "Source: https://www.deloitte.com/global/en/what-we-do/capabilities/gen-ai-services.html\n",
            "Title: Generative AI services\n",
            "Content: to stay ahead of evolving labor market needs Find out more GenAI training and upskilling Build new talent solutions to stay ahead of evolving labor market needs GenAI governance and risk management Operationalize legal and risk management practices & controls Find out more GenAI governance and risk management Operationalize legal and risk management practices & controls Optimize GenAI with managed services Maximize performance of models and platforms with leading AI operations practices and use of managed services Find out more Optimize GenAI with managed services Maximize performance of models and platforms with leading AI operations practices and use of managed services Client stories Investing in a more authentic customer experience Rakuten Securities, Deloitte Japan, and NVIDIA collaborate to build an innovative AI avatar that delivers an enhanced digital customer experience. Learn more Bringing AI to the forefront of a tech-driven food revolution Compass Group Australia and\n",
            "\n",
            "Source: https://cloud.google.com/transform/101-real-world-generative-ai-use-cases-from-industry-leaders\n",
            "Title: 185 real-world gen AI use cases from the world's leading organizations | Google Cloud Blog\n",
            "Content: product issues, reschedule order deliveries, manage Geek Squad subscriptions, and more; in-store and digital customer-service associates are also gaining gen-AI tools to better serve customers anywhere they need help. Watch the session to learn more. 28. The Central Texas Regional Mobility Authority is using Vertex AI to modernize transportation operations for a smoother, more efficient journey. 29. Etsy uses Vertex AI training to optimize their search recommendations and ads models, delivering better listing suggestions to buyers and helping sellers grow their businesses. 30. Golden State Warriors are using AI to improve the fan experience content in their Chase Center app. Watch the session to learn more. 31. IHG Hotels & Resorts is building a generative AI-powered chatbot to help guests easily plan their next vacation directly in the IHG One Rewards mobile app. Watch the session to learn more. 32. ING Bank aims to offer a superior customer experience and has developed a gen-AI\n",
            "\n",
            "Source: https://www.deloitte.com/global/en/what-we-do/capabilities/gen-ai-services.html\n",
            "Title: Generative AI services\n",
            "Content: Investing in a more authentic customer experience Rakuten Securities, Deloitte Japan, and NVIDIA collaborate to build an innovative AI avatar that delivers an enhanced digital customer experience. Learn more Bringing AI to the forefront of a tech-driven food revolution Compass Group Australia and Deloitte Australia launch an AI-enabled system for improving nutrition among older adults. Learn more It's not about the tool. Itâ€™s about the toolâ€™s capabilities. A state government program explores GenAIâ€™s potential to augment a digital transformation and help improve productivity. Learn more A new day for the night shift Kroger uses data analytics, AI, and ML tools to modernize its employee experience. Learn more Empowering sustainable food production with Generative AI Using GenAI to demystify the complexities of sustainable food production. Learn more Leveraging GenAI enterprise-wide: fast, straightforward, and secure with CAMPfire Bertelsmann, a global media, services, and education\n",
            "\n",
            "Source: https://www.deloitte.com/global/en/what-we-do/capabilities/gen-ai-services.html\n",
            "Title: Generative AI services\n",
            "Content: Investing in a more authentic customer experience Rakuten Securities, Deloitte Japan, and NVIDIA collaborate to build an innovative AI avatar that delivers an enhanced digital customer experience. Learn more Bringing AI to the forefront of a tech-driven food revolution Compass Group Australia and Deloitte Australia launch an AI-enabled system for improving nutrition among older adults. Learn more It's not about the tool. Itâ€™s about the toolâ€™s capabilities. A state government program explores GenAIâ€™s potential to augment a digital transformation and help improve productivity. Learn more A new day for the night shift Kroger uses data analytics, AI, and ML tools to modernize its employee experience. Learn more Empowering sustainable food production with Generative AI Using GenAI to demystify the complexities of sustainable food production. Learn more Leveraging GenAI enterprise-wide: fast, straightforward, and secure with CAMPfire Bertelsmann, a global media, services, and education\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InternalServerError",
          "evalue": "<html>\r\n<head><title>504 Gateway Time-out</title></head>\r\n<body>\r\n<center><h1>504 Gateway Time-out</h1></center>\r\n<hr><center>nginx/1.18.0 (Ubuntu)</center>\r\n</body>\r\n</html>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInternalServerError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-b28c95be7215>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mreport_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"research_report\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mreport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcosts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msources\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Report:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_future\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     96\u001b[0m                 raise RuntimeError(\n\u001b[1;32m     97\u001b[0m                     'Event loop stopped before Future completed.')\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__log_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_must_cancel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-b28c95be7215>\u001b[0m in \u001b[0;36mget_report\u001b[0;34m(query, report_type)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mresearcher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPTResearcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mresearch_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mresearcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconduct_research\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mresearcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gpt_researcher/agent.py\u001b[0m in \u001b[0;36mconduct_research\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     94\u001b[0m             )\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresearch_conductor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconduct_research\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gpt_researcher/skills/researcher.py\u001b[0m in \u001b[0;36mconduct_research\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Default web based research\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresearcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_context_by_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresearcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresearcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gpt_researcher/skills/researcher.py\u001b[0m in \u001b[0;36m__get_context_by_search\u001b[0;34m(self, query, scraped_data)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m# Using asyncio.gather to process the sub_queries asynchronously\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         context = await asyncio.gather(\n\u001b[0m\u001b[1;32m    163\u001b[0m             *[\n\u001b[1;32m    164\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__process_sub_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscraped_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/tasks.py\u001b[0m in \u001b[0;36m__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__wakeup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;31m# This may also be a cancellation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_must_cancel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gpt_researcher/skills/researcher.py\u001b[0m in \u001b[0;36m__process_sub_query\u001b[0;34m(self, sub_query, scraped_data)\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0mscraped_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__scrape_data_by_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresearcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_similar_content_by_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscraped_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresearcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gpt_researcher/skills/context_manager.py\u001b[0m in \u001b[0;36mget_similar_content_by_query\u001b[0;34m(self, query, pages)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mdocuments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresearcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         )\n\u001b[0;32m---> 26\u001b[0;31m         return await context_compressor.async_get_context(\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresearcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_costs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gpt_researcher/context/compression.py\u001b[0m in \u001b[0;36masync_get_context\u001b[0;34m(self, query, max_results, cost_callback)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcost_callback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mcost_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimate_embedding_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOPENAI_EMBEDDING_MODEL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mrelevant_docs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompressed_docs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pretty_print_docs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant_docs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/threads.py\u001b[0m in \u001b[0;36mto_thread\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontextvars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mfunc_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_in_executor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_call\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/futures.py\u001b[0m in \u001b[0;36m__await__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_asyncio_future_blocking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m  \u001b[0;31m# This tells Task to wait for completion.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"await wasn't used with future\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/tasks.py\u001b[0m in \u001b[0;36m__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__wakeup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;31m# This may also be a cancellation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__log_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/retrievers.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_retriever_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             run_manager.on_retriever_end(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/retrievers.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0m_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expects_other_args\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_arg_supported\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m                 result = self._get_relevant_documents(\n\u001b[0m\u001b[1;32m    248\u001b[0m                     \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/retrievers/contextual_compression.py\u001b[0m in \u001b[0;36m_get_relevant_documents\u001b[0;34m(self, query, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         )\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             compressed_docs = self.base_compressor.compress_documents(\n\u001b[0m\u001b[1;32m     49\u001b[0m                 \u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/retrievers/document_compressors/base.py\u001b[0m in \u001b[0;36mcompress_documents\u001b[0;34m(self, documents, query, callbacks)\u001b[0m\n\u001b[1;32m     37\u001b[0m                 )\n\u001b[1;32m     38\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0maccepts_callbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                     documents = _transformer.compress_documents(\n\u001b[0m\u001b[1;32m     40\u001b[0m                         \u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/retrievers/document_compressors/embeddings_filter.py\u001b[0m in \u001b[0;36mcompress_documents\u001b[0;34m(self, documents, query, callbacks)\u001b[0m\n\u001b[1;32m     71\u001b[0m             )\n\u001b[1;32m     72\u001b[0m         \u001b[0mstateful_documents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_stateful_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         embedded_documents = _get_embeddings_from_stateful_docs(\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstateful_documents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/document_transformers/embeddings_redundant_filter.py\u001b[0m in \u001b[0;36m_get_embeddings_from_stateful_docs\u001b[0;34m(embeddings, documents)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0membedded_documents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"embedded_doc\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         embedded_documents = embeddings.embed_documents(\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_content\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_openai/embeddings/base.py\u001b[0m in \u001b[0;36membed_documents\u001b[0;34m(self, texts, chunk_size)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0;31m#       than the maximum context and use length-safe embedding function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeployment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_len_safe_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m     async def aembed_documents(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_openai/embeddings/base.py\u001b[0m in \u001b[0;36m_get_len_safe_embeddings\u001b[0;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mbatched_embeddings\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m             response = self.client.create(\n\u001b[0m\u001b[1;32m    484\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_chunk_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invocation_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/embeddings.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0;34m\"/embeddings\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaybe_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_create_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbeddingCreateParams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1276\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m         )\n\u001b[0;32m-> 1278\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    956\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1042\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremaining_retries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1045\u001b[0m                     \u001b[0minput_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1094\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1042\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremaining_retries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1045\u001b[0m                     \u001b[0minput_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1094\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m         return self._process_response(\n",
            "\u001b[0;31mInternalServerError\u001b[0m: <html>\r\n<head><title>504 Gateway Time-out</title></head>\r\n<body>\r\n<center><h1>504 Gateway Time-out</h1></center>\r\n<hr><center>nginx/1.18.0 (Ubuntu)</center>\r\n</body>\r\n</html>"
          ]
        }
      ]
    }
  ]
}